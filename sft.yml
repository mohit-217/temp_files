base_model: Qwen/Qwen2.5-32B
trust_remote_code: true

gpu_memory_limit: 70GiB

# Model settings
chat_template: chatml

# Training settings
micro_batch_size: 8
num_epochs: 1
learning_rate: 0.0002
gradient_accumulation_steps: 32
optimizer: adamw_bnb_8bit
lr_scheduler: cosine
train_on_inputs: false
group_by_length: false

gradient_checkpointing: true
early_stopping_patience:
resume_from_checkpoint:
local_rank:

# Dataset settings
datasets:
  - path: cognitivecomputations/dolphin-r1
    type: chat_template
    chat_template: chatml
    field_messages: messages
    message_property_mappings:
      role: role
      content: content
    roles:
      user:
        - user
      assistant:
        - assistant
    data_files:
#      - dolphin-r1-nonreasoning.jsonl
      - dolphin-r1-reasoning-deepseek.jsonl
#      - dolphin-r1-reasoning-flash.jsonl
    trust_remote_code: True

val_set_size: 0.005
sequence_len: 2098
sample_packing: false
pad_to_sequence_len: true

# Logging & Monitoring
wandb_project:
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:
logging_steps: 1

# Evaluation & Saving
evals_per_epoch: 4
eval_table_size:
eval_max_new_tokens: 128
saves_per_epoch: 1

# Performance optimizations
xformers_attention:
flash_attention: true
s2_attention:
warmup_steps: 10

debug:
deepspeed: deepspeed_configs/zero3_bf16_cpuoffload_all.json
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:
